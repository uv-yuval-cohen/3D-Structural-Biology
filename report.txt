headline:
summary:
intro:

methods:
we go on to talk about methods leading our project.encountaring such problem, we wanted to develop our way into completing our goal. first we started with the data set of 4000 protein, 
a substantaly large amount, especially when a seperation into peptides is needed. After pre processing the data, extracting the peptides in relation to the proteins, and classifing them 
by their true label (nes containment), we moved on to the evaluation. Our strategy was to advance our model with the evaluation of the data acccuracy. processing a substantial amount of the 
proteins, dividing into peptides, embedding them, getting a score and a prediction using a changing threshold and finally getting a classification accuracy. with that the goalmis to progress 
the model, involving a well connected new data of negative examples to train the data better, and then improving our accuracy, everything towards the final goal of predicting the 
20K proteins, whether they contain nes or not. our workflow is based on evaluation and learning into progression, giving us a good balance of testing and correcting.
(chatgpt answer, needs review : Methods
In this project, we set out to develop a robust and systematic workflow for achieving our goal of accurately classifying NES-containing proteins. Throughout the process, we encountered several challenges, particularly due to the scale and complexity of the data. To address these, we designed a step-by-step approach that allowed us to iteratively improve our model.
We began by working with a dataset of 4,000 proteins — a substantial volume, especially considering the need to segment each protein into peptides. The initial stage involved comprehensive pre-processing of the data: extracting peptides corresponding to each protein, and accurately labeling them according to their true classification (presence or absence of NES elements).
Once the dataset was prepared, we moved into the evaluation phase. Our strategy focused on advancing the model through systematic evaluation of its predictive accuracy. This involved processing the dataset through several key stages:
dividing proteins into peptides,
generating embeddings for each peptide,
applying a scoring mechanism with a dynamic threshold to predict class labels,
and computing the overall classification accuracy.
A central component of our approach was the iterative improvement of the model. After each evaluation cycle, we refined the training data — particularly by introducing carefully curated negative examples — to ensure that the dataset became more balanced and informative. This continual refinement aimed to enhance the model’s ability to generalize and to increase predictive accuracy.
Ultimately, our goal is to apply this optimized model to a much larger dataset of 20,000 proteins, determining whether or not each contains NES elements. The entire workflow is designed around a cycle of evaluation and learning, which provides a balanced process of testing, correction, and progression toward increasingly reliable predictions.)


To address the challenge of identifying NES-containing proteins at scale, we developed a structured and iterative workflow grounded in evaluation and continuous improvement.

We began with a dataset of approximately 4,000 human proteins—a substantial volume, particularly given the need to segment each protein into overlapping peptides. In the preprocessing stage, each protein sequence was divided into sliding windows of 22 amino acids, generating a comprehensive set of candidate peptides. These peptides were then labeled according to their known NES status, based on external annotations.

Following this, we proceeded to model evaluation. Our pipeline involved:

Segmenting proteins into peptides,

Generating embeddings for each peptide using a pre-trained protein language model (e.g., ESM),

Applying a scoring function and a tunable threshold to predict NES presence,

Calculating classification performance metrics, including accuracy and AUC.

An important aspect of our approach was the refinement of the dataset between evaluation cycles. By carefully integrating high-quality negative examples, we aimed to improve the model's ability to distinguish NES-containing peptides from similar non-functional sequences. This feedback loop—evaluating, adjusting, and retraining—allowed us to steadily improve prediction quality.

Ultimately, this pipeline is designed to scale up to a larger set of ~20,000 human proteins. Our long-term objective is to accurately classify each protein based on its potential to contain NES elements. The combination of dynamic evaluation, model fine-tuning, and data-driven learning positions our workflow as a robust foundation for large-scale NES prediction.


